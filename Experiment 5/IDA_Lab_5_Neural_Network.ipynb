{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 5\n",
        "## Build a Neural Network model to predict whether tumor is malignant or benign for Breast Cancer Winconsin(Diagnostic) using Python."
      ],
      "metadata": {
        "id": "jXyvYDfWMAC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Inbuilt dataset\n",
        "Here we are using Inbuilt dataset for model\n",
        "## MLP Classifier\n",
        "The `MLPClassifier` is a multi-layer perceptron classifier used for classification tasks in machine learning. It employs neural network layers, activation functions, and optimization techniques to learn and predict class labels based on input data. It's customizable through hyperparameters and is trained on labeled datasets to make predictions."
      ],
      "metadata": {
        "id": "50GK0BjZHczl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For making dataframe\n",
        "import pandas as pd\n",
        "# For dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "# For splitting between training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Importing neural network\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "# For checking accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading the dataset\n",
        "cancer_data = load_breast_cancer()\n",
        "\n",
        "# Converting to dataframe\n",
        "data_df = pd.DataFrame(data = cancer_data.data,\n",
        "\t\t\t\t\tcolumns = cancer_data.feature_names)\n",
        "\n",
        "print(\"Dataset in Dataframe is:\\n\")\n",
        "print(data_df.head().T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKDMJE5mGd_5",
        "outputId": "5f34690a-2731-4ac3-fdec-3c7457cd248b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset in Dataframe is:\n",
            "\n",
            "                                   0            1            2           3  \\\n",
            "mean radius                17.990000    20.570000    19.690000   11.420000   \n",
            "mean texture               10.380000    17.770000    21.250000   20.380000   \n",
            "mean perimeter            122.800000   132.900000   130.000000   77.580000   \n",
            "mean area                1001.000000  1326.000000  1203.000000  386.100000   \n",
            "mean smoothness             0.118400     0.084740     0.109600    0.142500   \n",
            "mean compactness            0.277600     0.078640     0.159900    0.283900   \n",
            "mean concavity              0.300100     0.086900     0.197400    0.241400   \n",
            "mean concave points         0.147100     0.070170     0.127900    0.105200   \n",
            "mean symmetry               0.241900     0.181200     0.206900    0.259700   \n",
            "mean fractal dimension      0.078710     0.056670     0.059990    0.097440   \n",
            "radius error                1.095000     0.543500     0.745600    0.495600   \n",
            "texture error               0.905300     0.733900     0.786900    1.156000   \n",
            "perimeter error             8.589000     3.398000     4.585000    3.445000   \n",
            "area error                153.400000    74.080000    94.030000   27.230000   \n",
            "smoothness error            0.006399     0.005225     0.006150    0.009110   \n",
            "compactness error           0.049040     0.013080     0.040060    0.074580   \n",
            "concavity error             0.053730     0.018600     0.038320    0.056610   \n",
            "concave points error        0.015870     0.013400     0.020580    0.018670   \n",
            "symmetry error              0.030030     0.013890     0.022500    0.059630   \n",
            "fractal dimension error     0.006193     0.003532     0.004571    0.009208   \n",
            "worst radius               25.380000    24.990000    23.570000   14.910000   \n",
            "worst texture              17.330000    23.410000    25.530000   26.500000   \n",
            "worst perimeter           184.600000   158.800000   152.500000   98.870000   \n",
            "worst area               2019.000000  1956.000000  1709.000000  567.700000   \n",
            "worst smoothness            0.162200     0.123800     0.144400    0.209800   \n",
            "worst compactness           0.665600     0.186600     0.424500    0.866300   \n",
            "worst concavity             0.711900     0.241600     0.450400    0.686900   \n",
            "worst concave points        0.265400     0.186000     0.243000    0.257500   \n",
            "worst symmetry              0.460100     0.275000     0.361300    0.663800   \n",
            "worst fractal dimension     0.118900     0.089020     0.087580    0.173000   \n",
            "\n",
            "                                   4  \n",
            "mean radius                20.290000  \n",
            "mean texture               14.340000  \n",
            "mean perimeter            135.100000  \n",
            "mean area                1297.000000  \n",
            "mean smoothness             0.100300  \n",
            "mean compactness            0.132800  \n",
            "mean concavity              0.198000  \n",
            "mean concave points         0.104300  \n",
            "mean symmetry               0.180900  \n",
            "mean fractal dimension      0.058830  \n",
            "radius error                0.757200  \n",
            "texture error               0.781300  \n",
            "perimeter error             5.438000  \n",
            "area error                 94.440000  \n",
            "smoothness error            0.011490  \n",
            "compactness error           0.024610  \n",
            "concavity error             0.056880  \n",
            "concave points error        0.018850  \n",
            "symmetry error              0.017560  \n",
            "fractal dimension error     0.005115  \n",
            "worst radius               22.540000  \n",
            "worst texture              16.670000  \n",
            "worst perimeter           152.200000  \n",
            "worst area               1575.000000  \n",
            "worst smoothness            0.137400  \n",
            "worst compactness           0.205000  \n",
            "worst concavity             0.400000  \n",
            "worst concave points        0.162500  \n",
            "worst symmetry              0.236400  \n",
            "worst fractal dimension     0.076780  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting between Input and Output\n",
        "X,Y = cancer_data['data'], cancer_data['target']\n",
        "print(\"Input is:\\n\",X,\"\\n\\nOutput is:\\n\",Y)\n",
        "print(\"\\nShape of Input is:\",X.shape,\"\\nShape of Output is:\",Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKyf4c_KYH56",
        "outputId": "87280f35-05b7-4b74-c920-4ef8d4e98efa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input is:\n",
            " [[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]] \n",
            "\n",
            "Output is:\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
            "\n",
            "Shape of Input is: (569, 30) \n",
            "Shape of Output is: (569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a neural network classifier\n",
        "clf = MLPClassifier(hidden_layer_sizes=(30, 30, 30), max_iter=1000)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy of Neural Network is: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPr40qRmYVge",
        "outputId": "c92be5e8-3374-4a5d-d568-003e15873ba0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Neural Network is: 94.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using UCI dataset\n",
        "Here we are using UCI dataset for model\n",
        "## Keras Model\n",
        "`keras.Sequential` is a fundamental component in Keras, a deep learning library. It creates a linear stack of neural network layers for building models. Layers are added sequentially, and data flows from one to the next. It's widely used for building various types of neural networks, including feedforward and convolutional models."
      ],
      "metadata": {
        "id": "8qxLwi0TI5Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "# For normalizing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Import the dataset from an online resource\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
        "\n",
        "column_names = [\"ID\", \"Diagnosis\", \"Mean Radius\", \"Mean Texture\", \"Mean Perimeter\", \"Mean Area\", \"Mean Smoothness\",\n",
        "                \"Mean Compactness\", \"Mean Concavity\", \"Mean Concave Points\", \"Mean Symmetry\", \"Mean Fractal Dimension\",\n",
        "                \"SE Radius\", \"SE Texture\", \"SE Perimeter\", \"SE Area\", \"SE Smoothness\", \"SE Compactness\", \"SE Concavity\",\n",
        "                \"SE Concave Points\", \"SE Symmetry\", \"SE Fractal Dimension\", \"Worst Radius\", \"Worst Texture\",\n",
        "                \"Worst Perimeter\", \"Worst Area\", \"Worst Smoothness\", \"Worst Compactness\", \"Worst Concavity\",\n",
        "                \"Worst Concave Points\", \"Worst Symmetry\", \"Worst Fractal Dimension\"]\n",
        "data = pd.read_csv(url, header=None, names=column_names)\n",
        "\n",
        "# Drop the ID column as it's not useful for classification\n",
        "data = data.drop(columns=[\"ID\"])\n",
        "\n",
        "# Convert the 'Diagnosis' column to binary labels (Malignant = 1, Benign = 0)\n",
        "data['Diagnosis'] = data['Diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = data.drop(columns=[\"Diagnosis\"])\n",
        "y = data[\"Diagnosis\"]\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build a neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(30,)),  # Input layer with 30 features\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "-GlmYq2YYgtH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description of the code\n",
        "This code defines a neural network model for binary classification using TensorFlow's Keras API. Here's a breakdown of the model:\n",
        "\n",
        "1. **Input Layer**: This layer specifies the input shape with 30 features, corresponding to the number of columns in your dataset.\n",
        "\n",
        "2. **Hidden Layers**: The model has two hidden layers. The first hidden layer has 64 neurons with a ReLU (Rectified Linear Unit) activation function, and the second hidden layer has 32 neurons with a ReLU activation function. These layers are responsible for learning and capturing patterns in the data.\n",
        "\n",
        "3. **Output Layer**: The output layer has a single neuron with a sigmoid activation function. Sigmoid is commonly used for binary classification tasks because it squashes the output between 0 and 1, making it suitable for predicting probabilities. A value close to 1 indicates a prediction of \"Malignant,\" while a value close to 0 indicates \"Benign.\"\n",
        "\n",
        "So, this is a feedforward neural network with an input layer, two hidden layers, and an output layer designed for binary classification, specifically for classifying breast cancer diagnoses as either malignant (1) or benign (0)."
      ],
      "metadata": {
        "id": "-FM9dDnKJqwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4FHNUYRbzHP",
        "outputId": "5d670065-c7fc-4db3-9ca2-ca85dafa9e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 3s 31ms/step - loss: 0.5422 - accuracy: 0.7198 - val_loss: 0.3759 - val_accuracy: 0.8791\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2857 - accuracy: 0.9203 - val_loss: 0.2364 - val_accuracy: 0.9560\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1778 - accuracy: 0.9643 - val_loss: 0.1735 - val_accuracy: 0.9560\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.9780 - val_loss: 0.1400 - val_accuracy: 0.9670\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1014 - accuracy: 0.9835 - val_loss: 0.1214 - val_accuracy: 0.9670\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0852 - accuracy: 0.9808 - val_loss: 0.1109 - val_accuracy: 0.9670\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9835 - val_loss: 0.1033 - val_accuracy: 0.9560\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0665 - accuracy: 0.9863 - val_loss: 0.0982 - val_accuracy: 0.9560\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9863 - val_loss: 0.0933 - val_accuracy: 0.9560\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9863 - val_loss: 0.0900 - val_accuracy: 0.9670\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9863 - val_loss: 0.0875 - val_accuracy: 0.9780\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9863 - val_loss: 0.0867 - val_accuracy: 0.9780\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9890 - val_loss: 0.0851 - val_accuracy: 0.9780\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9890 - val_loss: 0.0836 - val_accuracy: 0.9780\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.0824 - val_accuracy: 0.9780\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.0812 - val_accuracy: 0.9780\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.0820 - val_accuracy: 0.9780\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9945 - val_loss: 0.0792 - val_accuracy: 0.9780\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 0.0797 - val_accuracy: 0.9780\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9945 - val_loss: 0.0794 - val_accuracy: 0.9780\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9945 - val_loss: 0.0800 - val_accuracy: 0.9780\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9945 - val_loss: 0.0803 - val_accuracy: 0.9780\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9945 - val_loss: 0.0811 - val_accuracy: 0.9780\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0819 - val_accuracy: 0.9670\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.0840 - val_accuracy: 0.9780\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.0846 - val_accuracy: 0.9670\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.0845 - val_accuracy: 0.9670\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0869 - val_accuracy: 0.9670\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0857 - val_accuracy: 0.9670\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0897 - val_accuracy: 0.9560\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.0914 - val_accuracy: 0.9560\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.0925 - val_accuracy: 0.9451\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9945 - val_loss: 0.0881 - val_accuracy: 0.9451\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.0923 - val_accuracy: 0.9451\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.0965 - val_accuracy: 0.9341\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.0979 - val_accuracy: 0.9341\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.0958 - val_accuracy: 0.9341\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0999 - val_accuracy: 0.9341\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1038 - val_accuracy: 0.9341\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1048 - val_accuracy: 0.9341\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9341\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9341\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9231\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9231\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9231\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9231\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9231\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9231\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9231\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description of the code\n",
        "In this code, the neural network model is compiled and trained using TensorFlow and Keras. Here's what each part of the code does:\n",
        "\n",
        "1. **Compiling the Model**:\n",
        "   - `model.compile(...)`: This step configures the training process of the model.\n",
        "   - `optimizer='adam'`: It specifies the optimization algorithm to use. \"Adam\" is a popular optimizer known for its efficiency in training deep neural networks.\n",
        "   - `loss='binary_crossentropy'`: This sets the loss function. In binary classification problems, \"binary_crossentropy\" is commonly used as the loss function.\n",
        "   - `metrics=['accuracy']`: This specifies the evaluation metric to monitor during training, which is accuracy in this case. It helps assess how well the model is performing.\n",
        "\n",
        "2. **Training the Model**:\n",
        "   - `model.fit(...)`: This function trains the neural network on the training data.\n",
        "   - `X_train` and `y_train` are the input features and labels for training.\n",
        "   - `epochs=50`: It defines the number of times the entire training dataset is passed forward and backward through the neural network during training (in this case, 50 epochs).\n",
        "   - `batch_size=32`: It specifies the number of training examples used in each update of the model's weights. Smaller batch sizes can lead to more accurate updates but can be slower.\n",
        "   - `validation_split=0.2`: This splits a portion (20%) of the training data for validation during training. It helps monitor the model's performance on data it hasn't seen during training to detect overfitting.\n",
        "\n",
        "The `history` object returned by `model.fit` contains information about the training process, including training and validation loss and accuracy for each epoch. We can use this information to visualize and analyze how well the model is learning from the data."
      ],
      "metadata": {
        "id": "dZsCE14HJ_vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy of the Neural Network is: {accuracy * 100}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"\\nClassification Report:\\n{class_report}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCDV9TowcQ0Q",
        "outputId": "59e31fda-1900-460c-89e9-d2f549feb895"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n",
            "Accuracy of the Neural Network is: 58.77192982456141\n",
            "\n",
            "Confusion Matrix:\n",
            "[[32 39]\n",
            " [ 8 35]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.45      0.58        71\n",
            "           1       0.47      0.81      0.60        43\n",
            "\n",
            "    accuracy                           0.59       114\n",
            "   macro avg       0.64      0.63      0.59       114\n",
            "weighted avg       0.68      0.59      0.58       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLmqXttYcXnd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}